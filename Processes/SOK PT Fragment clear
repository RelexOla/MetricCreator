1.

$read_trx = begin_trx;
table_to_recreate = :product_location_campaigns;
table_to_recreate_2 = :campaign_additions;
table_to_recreate_3 = :simulated_campaign_replenishments;

2.

begin_trx;
Trx.current.drop_table(table_to_recreate_3);
Trx.current.drop_table(table_to_recreate_2);
Trx.current.drop_table(table_to_recreate);
commit_trx;

3.
begin_trx;
source_table = $read_trx.get_table(table_to_recreate);
source_table.clone(table_to_recreate);
if source_table.model_class;
  FastormDb.database.model_mapping.put(table_to_recreate.to_s, source_table.model_class);
end;

source_table = $read_trx.get_table(table_to_recreate_2);
source_table.clone(table_to_recreate_2);
if source_table.model_class;
  FastormDb.database.model_mapping.put(table_to_recreate_2.to_s, source_table.model_class);
end;

source_table = $read_trx.get_table(table_to_recreate_3);
source_table.clone(table_to_recreate_3);
if source_table.model_class;
  FastormDb.database.model_mapping.put(table_to_recreate_3.to_s, source_table.model_class);
end;
commit_trx;
4.

$write_trx = begin_trx;
  $stop.set(1) rescue nil;
  cbe = org.codehaus.janino.ClassBodyEvaluator.new;
  cbe.setClassName('RowCopier');
  cbe.cook('
  import java.lang.Math;
  import java.lang.Runtime;
  import java.util.concurrent.atomic.AtomicLong;
  import org.apache.logging.log4j.Logger;
  import org.apache.logging.log4j.LogManager;
  import fi.relex.processor2.fastorm.cube.Cube;
  import fi.relex.processor2.fastorm.cube.CubeView;
  import fi.relex.processor2.fastorm.Row;
  import fi.relex.processor2.fastorm.Table;
  import fi.relex.processor2.fastorm.Trx;

      public static Logger logger = LogManager.getLogger(Cube.class);
      public long copyRows(final Table fromTable, final Table toTable, final String[] copyAttributes, final AtomicLong stop) {
          final Cube fromCube = fromTable.getTransaction().cube();
          final String fromTableName = fromTable.getName();
          final String toTableName = toTable.getName();
          final AtomicLong insertCount = new AtomicLong();
          logger.info("Fetching cube view data...");
          final long totalRows = fromCube.view(fromTableName).size();
          CubeView rows = fromCube.view(fromTableName);
          rows.parallelProcessRows(rows.new CubeViewProcessor("RowInserter") {
              public void process(Row oldRow) {
              if (stop.get() != 0) {
                      logger.info("Run stopped!");
                  throw new RuntimeException("Run stopped!");
                  }

                  Row row = new Row(toTableName);

                  for (int i = 0; i < copyAttributes.length; i++) {
                      row.setAttribute(copyAttributes[i], oldRow.getAttribute(copyAttributes[i]));
                  }
                  toTable.insert(row);
                  insertCount.incrementAndGet();

                  long inserts = insertCount.get();
                  if ((inserts % 10000) == 0) {
                      long free_m = Runtime.getRuntime().freeMemory() / 1024 / 1024;
                      long total_m = Runtime.getRuntime().totalMemory() / 1024 / 1024;
                      logger.info(inserts + " / " + totalRows + " (" + (Math.round(inserts * 1000.0 / totalRows) / 10.0) + "%) " +
                                  ", free mem: " + free_m + "M / " + total_m + "M");
                  }
              }
          });
          return insertCount.get();
      }
  ');
  $stop = AtomicLong.new;
  row_copier = cbe.getClazz;
  Job.start('copy_rows', "Copy rows") do;
    $stop.set(0);
    Rails.logger.info("Copying rows...");
    count = row_copier.new_instance.copy_rows(
      $read_trx.get_table(table_to_recreate.to_s),
      $write_trx.get_table(table_to_recreate.to_s),
      $read_trx.get_table(table_to_recreate.to_s).columns.keys.to_a.to_java(:string),
      $stop);
    Rails.logger.info("  -> #{count} inserted");
  end;


$write_trx.commit;